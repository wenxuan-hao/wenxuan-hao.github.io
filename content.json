{"meta":{"title":"Sparkle","subtitle":"code and life","description":null,"author":"郝文璇","url":"https://wenxuan-hao.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-12-22T15:07:47.000Z","updated":"2019-12-22T15:20:07.025Z","comments":true,"path":"categories/index.html","permalink":"https://wenxuan-hao.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-12-22T15:06:02.000Z","updated":"2019-12-22T15:20:35.829Z","comments":true,"path":"tags/index.html","permalink":"https://wenxuan-hao.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"what is 事务","slug":"what-is-事务","date":"2020-02-24T11:41:35.000Z","updated":"2020-02-24T11:44:43.832Z","comments":true,"path":"what-is-事务/","link":"","permalink":"https://wenxuan-hao.github.io/what-is-事务/","excerpt":"事务特性:ACID特性数据库管理系统中事务(transaction)的四个特性（分析时根据首字母缩写依次解释）：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。（执行单个逻辑功能的一组指令或操作称为事务）原子性指事务是一个不可再分割的工作单元，事务中的操作要么都发生，要么都不发生。","text":"事务特性:ACID特性数据库管理系统中事务(transaction)的四个特性（分析时根据首字母缩写依次解释）：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。（执行单个逻辑功能的一组指令或操作称为事务）原子性指事务是一个不可再分割的工作单元，事务中的操作要么都发生，要么都不发生。 一致性一致性是指在事务开始之前和事务结束以后，数据库的 完整性约束 没有被破坏。这是说数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。如A给B转账，不论转账的事务操作是否成功，其两者的存款总额不变（这是业务逻辑的一致性，至于数据库关系约束的完整性就更好理解了）。 隔离性多个事务并发访问时，事务之间是隔离的; 即事务A不会看到事务B的中间状态(脏读).完全的隔离性要求数据库同一时间只能执行一条事务, 但这样会严重影响性能. 持久性意味着在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中 事务并发问题脏读事务a读到了事务b还没有提交的数据 不可重复读前后读取结果不一致. 事务a读取过程中, 事务b进行了更新.解决: 锁住满足条件的行 mysql Innodb引擎默认的update语句默认加相关数据行的排它锁, 所以事务隔离级别为: 可重复读 幻读事务a 读完后 事务b新增了数据(事务a没有读到)解决: 锁表 事务隔离级别读未提交允许脏读 读已提交只能读到提交的事务数据(没有脏读, 但是可能会产生前后读取结果不一致) 可重复读不会产生前后读取结果不一致, 但是会有幻读 串行化最严格的的隔离级别, 要求所有事务严格串行执行, 不能并发执行","categories":[{"name":"基础原理","slug":"基础原理","permalink":"https://wenxuan-hao.github.io/categories/基础原理/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://wenxuan-hao.github.io/tags/事务/"},{"name":"ACID","slug":"ACID","permalink":"https://wenxuan-hao.github.io/tags/ACID/"}]},{"title":"乐观锁and悲观锁","slug":"乐观锁and悲观锁","date":"2020-02-24T11:41:07.000Z","updated":"2020-02-24T11:44:46.736Z","comments":true,"path":"乐观锁and悲观锁/","link":"","permalink":"https://wenxuan-hao.github.io/乐观锁and悲观锁/","excerpt":"乐观锁和悲观锁, 是并发控制了两种手段, 是一种思想. 悲观锁（Pessimistic Lock）在修改数据之前先锁定, 再修改. 之所以叫做悲观锁，是因为这是一种对数据的修改抱有悲观态度的并发控制方式。我们一般认为数据被并发修改的概率比较大，所以需要在修改之前先加锁。悲观锁的实现，往往依靠数据库提供的锁机制共享锁/排它锁悲观锁又可以分为共享锁和排它锁 共享锁(读锁): 多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。 排它锁(写锁): 如果一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据行读取和修改。","text":"乐观锁和悲观锁, 是并发控制了两种手段, 是一种思想. 悲观锁（Pessimistic Lock）在修改数据之前先锁定, 再修改. 之所以叫做悲观锁，是因为这是一种对数据的修改抱有悲观态度的并发控制方式。我们一般认为数据被并发修改的概率比较大，所以需要在修改之前先加锁。悲观锁的实现，往往依靠数据库提供的锁机制共享锁/排它锁悲观锁又可以分为共享锁和排它锁 共享锁(读锁): 多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。 排它锁(写锁): 如果一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据行读取和修改。 Mysql中实现悲观锁 读锁 select …. in share mode 写锁 select … for update update语句自动加写锁 乐观锁（ Optimistic Locking ）在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回给用户错误的信息，让用户决定如何去做。 乐观锁不会刻意使用数据库本身的锁机制，而是依据数据本身来保证数据的正确性。一般的实现乐观锁的方式就是记录数据版本。 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。 CASCAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。 CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。 更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。 ABA问题假如内存值原来是A，后来被一条线程改为B，最后又被改成了A，则CAS认为此内存值并没有发生改变，但实际上是有被其他线程改过的，这种情况对依赖过程值的情景的运算结果影响很大。解决的思路是引入版本号，每次变量更新都把版本号加一。(也可以使用时间戳, 因为时间戳具有天然的递增性) java中的解决方案: 123456789101112131415161718192021222324252627282930313233343536373839package concurrency;import java.util.concurrent.atomic.AtomicStampedReference;/** * @Author wenxuan.hao * @create 2020-02-15 00:14 */public class CAS_ABA &#123; private static AtomicStampedReference&lt;Integer&gt; atomicStampedRef = new AtomicStampedReference&lt;&gt;(1, 0); public static void main(String[] args)&#123; Thread main = new Thread(() -&gt; &#123; System.out.println(&quot;操作线程&quot; + Thread.currentThread() +&quot;,初始值 a = &quot; + atomicStampedRef.getReference()); int stamp = atomicStampedRef.getStamp(); //获取当前标识别 try &#123; Thread.sleep(1000); //等待1秒 ，以便让干扰线程执行 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean isCASSuccess = atomicStampedRef.compareAndSet(1,2,stamp,stamp +1); //此时expectedReference未发生改变，但是stamp已经被修改了,所以CAS失败 System.out.println(&quot;操作线程&quot; + Thread.currentThread() +&quot;,CAS操作结果: &quot; + isCASSuccess); &#125;,&quot;主操作线程&quot;); Thread other = new Thread(() -&gt; &#123; Thread.yield(); // 确保thread-main 优先执行 atomicStampedRef.compareAndSet(1,2,atomicStampedRef.getStamp(),atomicStampedRef.getStamp() +1); System.out.println(&quot;操作线程&quot; + Thread.currentThread() +&quot;,【increment】 ,值 = &quot;+ atomicStampedRef.getReference()); atomicStampedRef.compareAndSet(2,1,atomicStampedRef.getStamp(),atomicStampedRef.getStamp() +1); System.out.println(&quot;操作线程&quot; + Thread.currentThread() +&quot;,【decrement】 ,值 = &quot;+ atomicStampedRef.getReference()); &#125;,&quot;干扰线程&quot;); main.start(); other.start(); &#125;&#125;","categories":[{"name":"基础原理","slug":"基础原理","permalink":"https://wenxuan-hao.github.io/categories/基础原理/"}],"tags":[{"name":"乐观锁","slug":"乐观锁","permalink":"https://wenxuan-hao.github.io/tags/乐观锁/"},{"name":"悲观锁","slug":"悲观锁","permalink":"https://wenxuan-hao.github.io/tags/悲观锁/"}]},{"title":"mysql---索引","slug":"mysql-索引","date":"2020-02-24T11:34:58.000Z","updated":"2020-02-24T12:32:12.597Z","comments":true,"path":"mysql-索引/","link":"","permalink":"https://wenxuan-hao.github.io/mysql-索引/","excerpt":"常见索引模型 哈希表 适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。 有序数组 适用于静态存储引擎; 等值查询和范围查询效率都很高, 但是更新效率低. 搜索树 二叉搜索树查询和更新都是O(logn) N叉数适配磁盘的访问模式, N取决于数据块的大小 InnoDB索引在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。所以可以理解为 每一个表是好几棵B+树, 新建索引就是新建一颗B+数","text":"常见索引模型 哈希表 适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。 有序数组 适用于静态存储引擎; 等值查询和范围查询效率都很高, 但是更新效率低. 搜索树 二叉搜索树查询和更新都是O(logn) N叉数适配磁盘的访问模式, N取决于数据块的大小 InnoDB索引在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。所以可以理解为 每一个表是好几棵B+树, 新建索引就是新建一颗B+数 主键索引/聚簇索引叶子节点存储的是整行数据 自增主键自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT优点: 性能高: 每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。 存储空间小: 整形占4字节, 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小 非主键索引/二级索引叶子节点存储的是主键的值. ** 因此 覆盖索引 性能优化手段之一 即索引“覆盖了”我们的查询需求, 不需要回表操作 重建索引索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。 重建普通索引alter table T drop inedx k alter table T add index k重建主键索引alter table T engine=InnoDB不用两个alter的原因是, 不管是删除主键索引还是创建主键索引, 都会使表重建, 那么一个alter就是无用功.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://wenxuan-hao.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wenxuan-hao.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://wenxuan-hao.github.io/tags/索引/"},{"name":"InnoDB","slug":"InnoDB","permalink":"https://wenxuan-hao.github.io/tags/InnoDB/"},{"name":"B+树","slug":"B-树","permalink":"https://wenxuan-hao.github.io/tags/B-树/"}]},{"title":"mysql---事务","slug":"mysql-事务","date":"2020-02-24T11:34:48.000Z","updated":"2020-02-24T11:40:34.518Z","comments":true,"path":"mysql-事务/","link":"","permalink":"https://wenxuan-hao.github.io/mysql-事务/","excerpt":"事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。而MyISAM 引擎就不支持事务. 事物操作 显示启动 1234begin / start transactionrollbackcommit commit work and chain // 提交事务后自动启动下一个事务, 省去了再次被begin的开销; 适用于频繁使用事务的业务 配置启动 1set autocommit=0 注意: 这种方法下, 任何语句都会开启事务, 直到显示commit / rollback 查询系统长事务 12// 查询时间超过60s的长事务select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 查询事务隔离级别 1show variables like &apos;transaction_isolation&apos;;","text":"事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。而MyISAM 引擎就不支持事务. 事物操作 显示启动 1234begin / start transactionrollbackcommit commit work and chain // 提交事务后自动启动下一个事务, 省去了再次被begin的开销; 适用于频繁使用事务的业务 配置启动 1set autocommit=0 注意: 这种方法下, 任何语句都会开启事务, 直到显示commit / rollback 查询系统长事务 12// 查询时间超过60s的长事务select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 查询事务隔离级别 1show variables like &apos;transaction_isolation&apos;; 实现原理 (回滚日志, MVCC)在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值. 在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的 多版本并发控制（MVCC） 。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。 当系统里没有比这个回滚日志更早的 read-view 的时候, 即不再有事务需要这些日志, 它就会被删除.因此, 尽量不要使用长事务, 因为他会导致存在很多老的事务视图, 而在该事务提交之前, 所要用到的回滚日志都需要保留着. 读未提交: 直接返回记录上的最新值, 不使用视图 读提交: 执行每条sql语句时创建视图 可重复读: 事务启动时创建视图, 并在整个事务期间都使用这张图 串行化: 使用加锁控制, 不使用视图 如何避免长事务的影响开发端手段 确认是否使用了set autocommit=0 因为有些框架会自动设置, 可以通过开启 general_long, 随便跑一个业务逻辑, 通过日志来确认. 确认是否有只读事务 某些框架会会习惯将所有语句包裹在 begin/commit中, 或者将好几个select语句放到事务中, 打包执行. 通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间服务端手段 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。 关于 innodb_undo_tablespaces 参数: http://blog.itpub.net/31493717/viewspace-2154774/ 锁全局读锁让全库处于只读的状态, 所有的数据更新语句, 数据定义语句都会被阻塞; 命令Flush tables with read lock全库逻辑备份全库逻辑备份, 是全局读锁的典型使用场景. 如果不加锁, 有可能会造成多个表逻辑的不一致 逻辑备份 mysqldump 把表中的数据select出来进行存储, 无关存储引擎等. 但是恢复速度慢. 物理备份 xtrabackup 基于实际文件的备份 对与Innodb这种支持事务的存储引擎, 可以使用 可重复读 隔离级别来解决表逻辑不一致的问题, 且相比于全局读锁的优点是: 由于MVCC的支持, 数据库依旧可以更新.但是对于像MyISAM这种不支持事务的, 只能使用全局读锁的方式. 为什么不用全局配置?set global readonly=true也可以设置库为只读状态, 但不建议使用.因为如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。 mysqldump阅读资料https://www.cnblogs.com/yanjieli/p/9807011.html 表锁表锁粒度太大, 一般不用; 但是对于不支持行锁的存储引擎, 只能使用表锁. eg.MyISAM 123lock tables … read/write // 加锁unlock tables //释放锁, 客户端断开连接也会释放锁 注意lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。例如: lock tables t1 read, t2 write;, 则该线程接下来只能对t1进行读操作, 对t2进行读写操作, 而不能访问其他的表. 元数据锁 为了防止DDL和DML并发的冲突 在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。且MDL锁要等事务提交才会释放. 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 行锁MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。行锁就是针对数据表中行记录的锁, 比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。 两阶段锁需要的时候加锁(update), 事务结束时释放(而不是不需要的时候), 即所有的操作需要的行锁都是在事务提交的时候才释放的因此, 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://wenxuan-hao.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wenxuan-hao.github.io/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"https://wenxuan-hao.github.io/tags/事务/"},{"name":"MVCC","slug":"MVCC","permalink":"https://wenxuan-hao.github.io/tags/MVCC/"},{"name":"两阶段锁","slug":"两阶段锁","permalink":"https://wenxuan-hao.github.io/tags/两阶段锁/"}]},{"title":"redis---高可用","slug":"redis-高可用","date":"2020-02-24T11:30:11.000Z","updated":"2020-02-24T11:55:45.930Z","comments":true,"path":"redis-高可用/","link":"","permalink":"https://wenxuan-hao.github.io/redis-高可用/","excerpt":"概述复制复制是高可用 Redis 的基础，哨兵 和 集群 都是在 复制基础 上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡缺点: 故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制 哨兵在复制的基础上，哨兵实现了 自动化故障恢复缺点: 写操作无法负载均衡、存储能力受到单机的限制 集群解决了 写操作无法负载均衡、存储能力受到单机的限制","text":"概述复制复制是高可用 Redis 的基础，哨兵 和 集群 都是在 复制基础 上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡缺点: 故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制 哨兵在复制的基础上，哨兵实现了 自动化故障恢复缺点: 写操作无法负载均衡、存储能力受到单机的限制 集群解决了 写操作无法负载均衡、存储能力受到单机的限制 Sentinel监控主服务器及其从服务器, 当主服务器下线时, 自动将某个从服务器升级为主服务器; 此外, sentinel还会继续监视下线的服务器, 等到它重新上线时, 将其设置为新的主服务器的从服务器. 命令客户端可以对sentinel服务器执行的全部命令 ping sentinel info subscribe / unsubscribe psubscribe / punsubscribe (模式订阅) 工作原理节点发现 初始配置 sentinel只需要配置主服务器的地址信息, 通过info获得从服务器信息, 通过订阅__sentinel__:hello频道获取其他sentinel节点信息 根据配置获取所监视的主服务器的地址, 向其创建两个异步网络连接 命令连接: 用于向服务器发送命令, 接受命令 订阅连接: 订阅服务器的 __sentinel__:hello 频道 sentinel默认以每十秒一次的频率, 向主服务器发送 info 命令; 通过回复, 可得知主服务器具体信息, 以及从服务具体信息 若从服务对应实例已存在, sentinel会对从服务器的实例结构进行更新 若不存在, 则说明是新发现的从服务器, sentinel会创建新实例结构, 并创建订阅连接以及命令连接 sentinel默认以每十秒一次的频率, 向从服务器发送info命令, 得到从服务具体信息, 并更新其实例. sentinel默认以两秒一次的频率, 向所监控的服务器 publish __sentinel__:hello sentinel的ip:port 配置纪元, 目标服务器的ip:port 配置纪元 则所有监控该服务器的sentinel节点都会收到这条信息 当一个Sentinel接收到其他Sentinel发来的信息时，目标Sentinel会从信息中分析并提取出以下两方面参数： 与Sentinel有关的参数：源Sentinel的IP地址、端口号、运行ID和配置纪元。 与主服务器有关的参数：源Sentinel正在监视的主服务器的名字、IP地址、端口号和配置纪元。 因此, 监视同一个主服务器的sentinel节点可以自动发现对方, 而无需配置 当一个sentinel发现新的sentinel时, 会创建其实例, 以及命令连接 sentinel之间不会创建订阅连接 自动化故障恢复 Sentinel会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器、从服务器、其他Sentinel在内）发送PING命令 有效回复：实例返回+PONG、-LOADING、-MASTERDOWN三种回复的其中一种 若在 down-after-milliseconds 时间内没有得到有效回复, 则sentinel标识该服务器为 主观下线状态 判断为主观下线后, 会询问其他sentinel节点; 当该sentinel接收到超过 quorum 数量的主观下线判断后, 就会判定为 客观下线. 当一个主服务器被判断为客观下线时，监视这个下线主服务器的各个Sentinel会进行协商，选举出一个领头Sentinel，并由领头Sentinel对下线主服务器执行故障转移操作 故障转移操作主要分为三步: 在已下线主服务器属下的所有从服务器里面，挑选出一个从服务器，并将其转换为主服务器。 12发送 slave of no one 命令并频繁info, 当返回的信息的role从slave变为master, 代表升级成功 让已下线主服务器属下的所有从服务器改为复制新的主服务器。 1发送 slave of 主服务器ip 主服务器port 将已下线主服务器设置为新的主服务器的从服务器，当这个旧的主服务器重新上线时，它就会成为新的主服务器的从服务器。 集群","categories":[{"name":"redis","slug":"redis","permalink":"https://wenxuan-hao.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wenxuan-hao.github.io/tags/redis/"},{"name":"哨兵","slug":"哨兵","permalink":"https://wenxuan-hao.github.io/tags/哨兵/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://wenxuan-hao.github.io/tags/Sentinel/"},{"name":"redis集群","slug":"redis集群","permalink":"https://wenxuan-hao.github.io/tags/redis集群/"}]},{"title":"redis---事务","slug":"redis-事务","date":"2020-02-24T11:30:02.000Z","updated":"2020-02-24T12:34:21.131Z","comments":true,"path":"redis-事务/","link":"","permalink":"https://wenxuan-hao.github.io/redis-事务/","excerpt":"使用为了保证原子性, redis提供了简单的事务. 但不支持事务回滚 123multi 开始事务, 之后输入命令, 会放入队列而不是真正的执行discard 停止事务exec 执行事务, 真正执行命令","text":"使用为了保证原子性, redis提供了简单的事务. 但不支持事务回滚 123multi 开始事务, 之后输入命令, 会放入队列而不是真正的执行discard 停止事务exec 执行事务, 真正执行命令 细节 在事务中, 如果有一条命令执行错误, 其他的命令也会正常执行即redis的事务不满足原子性, 但满足隔离性(redis为单线程, 一个事务内的指定可以得到严格的串行化执行) 使用discard停止事务后, 之前提交的命令不会执行流水线vs事务流水线: 将多个命令打包, 然后一并发送到服务器事务: 将多个命令打包, 然后让服务器一并执行客户端使用在客户端中使用事务, 很多库的实现方式是用pipline将命令打包发送到服务器, 并在服务端用事务执行. 这样就能实现多个命令的打包发送, 以及打包执行. watch命令watch命令可以对数据库的key进行监视, 如果在exec之前, 这些键的值发生了变化, 那么该事务执行失败. 取消watch unwatch命令 exec命令执行事务后, 监视自动取消 discard终止事务, 监视自动取消 使用watch实现乐观锁用被监视的key当做锁, 如果键值发生改变, 事务执行失败; 分布式锁是一种悲观锁 案例假设我们对redis中的数据进行倍数操作; 如果是加减操作, 可以直接用incrby, 不会产生并发问题. 但是redis并没有提供倍数操作的指令, 我们只能先取值, 运算, 再存入. 这就会产生并发问题. 解决方法可以用watch 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package redis;import redis.clients.jedis.Jedis;import redis.clients.jedis.Transaction;import java.util.List;/** * @Author wenxuan.hao * @create 2020-02-16 00:31 */public class Watch &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(); String userId = &quot;abc&quot;; String key = keyFor(userId); jedis.setnx(key, String.valueOf(5)); System.out.println(doubleAccount(jedis, userId)); jedis.close(); &#125; public static int doubleAccount(Jedis jedis, String userId) &#123; String key = keyFor(userId); // 若加锁失败, 自旋 while (true) &#123; jedis.watch(key); int value = Integer.parseInt(jedis.get(key)); value *= 2; // 加倍 // 事务 Transaction tx = jedis.multi(); tx.set(key, String.valueOf(value)); List&lt;Object&gt; res = tx.exec(); // 因为对key进行了watch, 如果key没有改变, 更新成功, 跳出循环 if (res != null) &#123; break; // 成功了 &#125; &#125; return Integer.parseInt(jedis.get(key)); // 重新获取余额 &#125; public static String keyFor(String userId) &#123; return String.format(&quot;account_%s&quot;, userId); &#125;&#125;","categories":[{"name":"redis","slug":"redis","permalink":"https://wenxuan-hao.github.io/categories/redis/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://wenxuan-hao.github.io/tags/事务/"},{"name":"redis","slug":"redis","permalink":"https://wenxuan-hao.github.io/tags/redis/"},{"name":"watch命令","slug":"watch命令","permalink":"https://wenxuan-hao.github.io/tags/watch命令/"}]},{"title":"redis---队列","slug":"redis-队列","date":"2020-02-24T11:29:35.000Z","updated":"2020-02-24T11:40:33.650Z","comments":true,"path":"redis-队列/","link":"","permalink":"https://wenxuan-hao.github.io/redis-队列/","excerpt":"消息队列 注意, 如果对消息的可靠性有极致追求, 则不建议使用redis作为队列 直接用redis的list结构来实现, 生产者 rpush, 消费者 lpop","text":"消息队列 注意, 如果对消息的可靠性有极致追求, 则不建议使用redis作为队列 直接用redis的list结构来实现, 生产者 rpush, 消费者 lpop 问题1: 空队列如果队列为空, 消费者还一直空轮训, 会拉高客户端cpu, 以及redis的QPS. 解决 sleep()解决, 但是会导致消息的延迟增大 blpop 阻塞读. 一旦数据准备好, 就会立刻醒来, 消息延迟几乎为0 问题2: 空连接自动断开使用 blpop 时, 若消息一直没有准备好, redis的客户端连接会变成闲置连接. 闲置时间过久, 服务器会自动断开连接, 这时blpop就会抛出异常 解决捕获异常, 并重试 延时队列带有延时功能的消息队列场景案例: 用户下单30分钟后未付款, 自动关闭订单 实现使用zset, score为到期处理的时间, value为序列化的消息. 多线程轮询zset获取到期任务进行处理. 多线程是可用性保障, 为了防止一个线程挂了还有其他的线程可以处理. 因为多线程抢占, 所以还要考虑一个并发性问题, 保证消息不能被处理多次, 这里采用zrem, 因为一个值只能被删除一次. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package redis;import java.lang.reflect.Type;import java.util.Set;import java.util.UUID;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.TypeReference;import redis.clients.jedis.Jedis;/** * @Author wenxuan.hao * @create 2020-02-13 22:03 */public class RedisDelayingQueue&lt;T&gt; &#123; static class TaskItem&lt;T&gt; &#123; public String id; public T msg; &#125; // fastjson 序列化对象中存在 generic 类型时，需要使用 TypeReference private Type TaskType = new TypeReference&lt;TaskItem&lt;T&gt;&gt;()&#123;&#125;.getType(); private Jedis jedis; private String queueKey; public RedisDelayingQueue(Jedis jedis, String queueKey) &#123; this.jedis = jedis; this.queueKey = queueKey; &#125; public void delay(T msg) &#123; TaskItem&lt;T&gt; task = new TaskItem&lt;T&gt;(); task.id = UUID.randomUUID().toString(); // 分配唯一的 uuid task.msg = msg; String s = JSON.toJSONString(task); // fastjson 序列化 jedis.zadd(queueKey, System.currentTimeMillis() + 5000, s); // 塞入延时队列 ,5s 后再试 &#125; public void loop() &#123; while (!Thread.interrupted()) &#123; // 只取一条 Set&lt;String&gt; values = jedis.zrangeByScore(queueKey, 0, System.currentTimeMillis(), 0, 1); // 没取到 if (values.isEmpty()) &#123; try &#123; Thread.sleep(500); // 歇会继续 &#125; catch (InterruptedException e) &#123; break; &#125; continue; &#125; // 取到了 String s = values.iterator().next(); if (jedis.zrem(queueKey, s) &gt; 0) &#123; // 防止一条数据被处理多次, 因为只能成功删除一次 TaskItem&lt;T&gt; task = JSON.parseObject(s, TaskType); // fastjson 反序列化 this.handleMsg(task.msg); &#125; &#125; &#125; public void handleMsg(T msg) &#123; System.out.println(msg); &#125; public static void main(String[] args) &#123; Jedis jedis = new Jedis(); RedisDelayingQueue&lt;String&gt; queue = new RedisDelayingQueue&lt;&gt;(jedis, &quot;q-demo&quot;); Thread producer = new Thread() &#123; public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; queue.delay(&quot;codehole&quot; + i); &#125; &#125; &#125;; Thread consumer = new Thread() &#123; public void run() &#123; queue.loop(); &#125; &#125;; producer.start(); consumer.start(); try &#123; producer.join(); Thread.sleep(6000); consumer.interrupt(); consumer.join(); &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125;","categories":[{"name":"redis","slug":"redis","permalink":"https://wenxuan-hao.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wenxuan-hao.github.io/tags/redis/"},{"name":"消息队列","slug":"消息队列","permalink":"https://wenxuan-hao.github.io/tags/消息队列/"},{"name":"延迟队列","slug":"延迟队列","permalink":"https://wenxuan-hao.github.io/tags/延迟队列/"}]},{"title":"redis---分布式锁","slug":"redis-分布式锁","date":"2020-02-24T11:29:29.000Z","updated":"2020-02-24T11:40:32.718Z","comments":true,"path":"redis-分布式锁/","link":"","permalink":"https://wenxuan-hao.github.io/redis-分布式锁/","excerpt":"分布式锁利用setnx, key若存在, 则创建失败的特性 12setnx lock truedel lock","text":"分布式锁利用setnx, key若存在, 则创建失败的特性 12setnx lock truedel lock 问题1: 死锁若在del之前出现问题, 则该锁永远无法释放, 产生死锁 解决:给该key加上超时时间; 则从锁层面来说, 超时自动释放 123setnx lock trueexpire lock 5del lock 问题2: 原子性问题若setnx与expire之间挂掉了怎么办? 解决:redis 2.8 版本之前: 开源社区的分布式锁libraryredis 2.8 版本: 12set lock true ex 5 nxdel lock 问题3: 超时问题线程1获得锁后超时, 锁释放, 线程2持有锁. 但此时线程1未执行完的逻辑还是可以执行的, 线程1继续执行, 将线程2持有的锁del掉. 解决给锁赋值一个随机数, 锁释放前先看随机数是否匹配 (以此来验证是不是同一个线程释放的锁) 1234tag = random()if redis.set(&quot;lock&quot;, tag, nx=true, ex=5): do somthing... redis.delifequals(key, tag) 但是, redis.delifequals(key, tag) 中匹配value和删除key不是一个原子操作, 有可能存在get到value后, 值发生改变, 然后错误的del. 这里可以使用lua脚本来处理","categories":[{"name":"redis","slug":"redis","permalink":"https://wenxuan-hao.github.io/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://wenxuan-hao.github.io/tags/redis/"},{"name":"分布式锁","slug":"分布式锁","permalink":"https://wenxuan-hao.github.io/tags/分布式锁/"}]},{"title":"网络相关的linux命令","slug":"网络相关的linux命令","date":"2020-02-12T14:45:29.000Z","updated":"2020-03-01T13:18:29.504Z","comments":true,"path":"网络相关的linux命令/","link":"","permalink":"https://wenxuan-hao.github.io/网络相关的linux命令/","excerpt":"telnet基于http的网络协议 检查端口是否可达, 发送http请求telnet ip port nc 检查端口是否可达 123nc -zv ip port -v 显示详情-z 不发送数据包, 三次握手后退出 发送http请求nc ip port 监听本地端口 nc -l -p 端口号 netstatnetstat是基于Netstat这个命令行工具的指令，它可以用来查询系统上的网络套接字连接情况，包括tcp,udp以及Unix套接字；另外它还能列出路由表，接口状态和多播成员等信息。","text":"telnet基于http的网络协议 检查端口是否可达, 发送http请求telnet ip port nc 检查端口是否可达 123nc -zv ip port -v 显示详情-z 不发送数据包, 三次握手后退出 发送http请求nc ip port 监听本地端口 nc -l -p 端口号 netstatnetstat是基于Netstat这个命令行工具的指令，它可以用来查询系统上的网络套接字连接情况，包括tcp,udp以及Unix套接字；另外它还能列出路由表，接口状态和多播成员等信息。 检查端口占用netstat -ap | grep :prot 列出网卡信息netstat -i 显示 8080 端口所有处于 ESTABLISHED 状态的连接netstat -atnp | grep &quot;:8080&quot; | grep ESTABLISHED 统计处于各个状态的连接个数netstat -ant | awk &#39;{print $6}&#39; | sort | uniq -c | sort -n lsoflsof(list open files)是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 检查端口占用 1234lsof -n -P -i:port -n 不将ip解析为域名-P 不将port解析为service name-i:port 指定端口","categories":[{"name":"linux","slug":"linux","permalink":"https://wenxuan-hao.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://wenxuan-hao.github.io/tags/linux/"},{"name":"网络","slug":"网络","permalink":"https://wenxuan-hao.github.io/tags/网络/"}]},{"title":"exec命令","slug":"exec命令","date":"2019-12-31T02:56:02.000Z","updated":"2020-02-09T08:02:33.316Z","comments":true,"path":"exec命令/","link":"","permalink":"https://wenxuan-hao.github.io/exec命令/","excerpt":"execexec共有三种用法 执行程序 文件重定向 当做find命令的一个选项","text":"execexec共有三种用法 执行程序 文件重定向 当做find命令的一个选项 执行命令系统调用exec是以新的进程去代替原来的进程，但进程的PID保持不变。因此，可以这样认为，exec系统调用并没有创建新的进程，只是替换了原来进程上下文的内容。原进程的代码段，数据段，堆栈段被新的进程所代替。即: 使用exec执行命令, 将不会启动新的shell, 而是用被执行命令替代当前shell进程, 命令执行结束后, shell退出.常用场景: 我们一般将exec写在脚本中, bash执行该脚本; 这样会为该脚本创建一个sub shell去执行, 当执行到exec时, 该子脚本进程就会替换为相应的exec命令. 执行exec系统调用，一般都是这样，用fork()函数新建立一个进程，然后让进程去执行exec调用。我们知道，在fork()建立新进程之后，父进各与子进程共享代码段，但数据空间是分开的，但父进程会把自己数据空间的内容copy到子进程中去，还有上下文也会copy到子进程中去。而为了提高效率，采用一种写时copy的策略，即创建子进程的时候，并不copy父进程的地址空间，父子进程拥有共同的地址空间，只有当子进程需要写入数据时(如向缓冲区写入数据),这时候会复制地址空间，复制缓冲区到子进程中去。从而父子进程拥有独立的地址空间。而对于fork()之后执行exec后，这种策略能够很好的提高效率，如果一开始就copy,那么exec之后，子进程的数据会被放弃，被新的进程所代替。 bash source . 都可以执行脚本, 区别在于source和.不会为脚本新建shell, 而是在当前shell中执行; 文件重定向我们先看一下/dev/fd目录:默认会有这四个项： 0是标准输入，默认是键盘。 stdin 1是标准输出，默认是屏幕/dev/tty stdout 2是标准错误，默认也是屏幕 stderr 例子: 1234exec &gt;file //将当前shell的标准输出到file文件中, 因为&gt;默认为1exec 4&gt;file //将写入fd4中的内容写入file中exec 5&lt;&amp;4 //创建fd4的拷贝fd5exec 3&lt;&amp;- //关闭fd3 find命令1234// 在当前目录下(包含子目录)，查找所有txt文件并找出含有字符串&quot;bin&quot;的行 find ./ -name &quot;*.txt&quot; -exec grep &quot;bin&quot; &#123;&#125; \\; // 在当前目录下(包含子目录)，删除所有txt文件 find ./ -name &quot;*.txt&quot; -exec rm &#123;&#125; \\;","categories":[{"name":"linux","slug":"linux","permalink":"https://wenxuan-hao.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://wenxuan-hao.github.io/tags/linux/"},{"name":"exec命令","slug":"exec命令","permalink":"https://wenxuan-hao.github.io/tags/exec命令/"}]},{"title":"软链接/硬链接","slug":"软硬链接","date":"2019-12-24T02:56:02.000Z","updated":"2020-02-09T08:03:23.431Z","comments":true,"path":"软硬链接/","link":"","permalink":"https://wenxuan-hao.github.io/软硬链接/","excerpt":"inode文件都有文件名与数据，这在 Linux 上被分成两个部分：用户数据 (user data) 与元数据 (metadata)。用户数据，即文件数据块 (data block)，数据块是记录文件真实内容的地方；而元数据则是文件的附加属性，如文件大小、创建时间、所有者等信息。在 Linux 中，元数据中的 inode 号（inode 是文件元数据的一部分但其并不包含文件名，inode 号即索引节点号）才是文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过 inode 号寻找正确的文件数据块。图 1.展示了程序通过文件名获取文件内容的过程. ls -i 查看inode号","text":"inode文件都有文件名与数据，这在 Linux 上被分成两个部分：用户数据 (user data) 与元数据 (metadata)。用户数据，即文件数据块 (data block)，数据块是记录文件真实内容的地方；而元数据则是文件的附加属性，如文件大小、创建时间、所有者等信息。在 Linux 中，元数据中的 inode 号（inode 是文件元数据的一部分但其并不包含文件名，inode 号即索引节点号）才是文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过 inode 号寻找正确的文件数据块。图 1.展示了程序通过文件名获取文件内容的过程. ls -i 查看inode号 硬链接硬链接是有着相同 inode 号仅文件名不同的文件，因此硬链接存在以下几点特性: 文件有相同的 inode 及 data block； 只能对已存在的文件进行创建； 不能交叉文件系统进行硬链接的创建； 不能对目录进行创建，只可对文件创建； 删除一个硬链接文件并不影响其他有相同 inode 号的文件。 命令: ln oldfile newfile 软连接软链接与硬链接不同，若文件用户数据块中存放的内容是另一文件的路径名的指向，则该文件就是软连接。软链接就是一个普通文件，只是数据块内容有点特殊。软链接有着自己的 inode 号以及用户数据块（见 图 2.）。因此软链接的创建与使用没有类似硬链接的诸多限制： 软链接有自己的文件属性及权限等； 可对不存在的文件或目录创建软链接； 软链接可交叉文件系统； 软链接可对文件或目录创建； 创建软链接时，链接计数 i_nlink 不会增加； 删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。 命令: ln -s oldfile newfile 相关命令 查找某文件的所有软连接 find dir -lname filename 查找与某文件有相同inode的所有硬链接 find dir -samefile filename 查找某一inode的所有硬链接 find dir -inum inode 查看某一目录的所有连接文件 find dir -type -l -ls //-ls为查看文件具体信息","categories":[{"name":"linux","slug":"linux","permalink":"https://wenxuan-hao.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://wenxuan-hao.github.io/tags/linux/"},{"name":"文件系统","slug":"文件系统","permalink":"https://wenxuan-hao.github.io/tags/文件系统/"}]},{"title":"计算机网路基础回顾","slug":"计算机网路基础回顾","date":"2019-12-23T04:13:28.000Z","updated":"2020-02-12T06:48:04.896Z","comments":true,"path":"计算机网路基础回顾/","link":"","permalink":"https://wenxuan-hao.github.io/计算机网路基础回顾/","excerpt":"本文是对计算机网络基础做的一次整体的梳理","text":"本文是对计算机网络基础做的一次整体的梳理 osi七层模型 应用层: 针对特定应用的协议 表示层: 设备固有数据格式 → 网络标准数据格式 会话层: 通信管理, 负责建立和断开通信连接 传输层: 可靠传输 网络层: 地址管理/路由选择 数据链路层: 数据帧 &lt;-&gt; 01比特流 的转化 物理层: 01比特流 &lt;-&gt; 电子信号 的转化 设备中继器/ 集线器: 1层交换设备 区别: 集线器有多端口, 中继器只有两个 作用: 物理层面延长网络, 信号放大 特点: 逐比特转发, 无法改变传输速度, 无差错控制, 不能连接传播速度不同的网络 网桥/ 交换机: 2层交换设备 区别: 交换机有多个端口, 网桥只有两个 作用: 识别数据帧 -&gt; 存储于内存 -&gt; 重新生成新的帧转发给另一网段 特点: 不限制连接网段个数, 可以连接传输速率不同的网段, 具有差错检测, 地址自学习功能 路由器: 3层交换设备4-7层交换机 以传输层及以上的协议为基础, 分析收发数据, 并做特定处理 eg. 负责均衡器, 带宽控制 网关 传输层及其以上: 转发+转换数据 eg. 手机电子邮件和互联网邮件的转换 数据链路层作用提供直连的两个设备间的通信功能, 在互联的同一种数据链路的节点之间进行包传递 MAC地址 网络层: ip协议作用可以跨过不同的数据链路, 在复杂的网络环境中将数据包发送给目标地址 ip地址格式组成: 网络标识 : 主机标识 (路由器只根据网络标识进行转发)表示: xx.xx.xx.xx / xx(代表网络标识的位数)首部: 版本: 标识ip版本, ipv4该值为4 首部长度: 单位为4字节; 当可选项为空时, 该值为5, 即20字节 总长度: 首部+数据的总长度 标识, 标志, 片偏移 共同控制数据包的分片与重组 标识: 同一个数据包标识相同 标志: 分片的相关信息 片偏移: 每个分片相对于原始数据的位置. 第一个分片该值为0 生存时间: 每经过一个路由器, TTL减1, 变成0时丢弃该包 协议字段: 表示ip首部的下一个首部隶属于那个协议, eg. tcp/udp/icmp…分类 一个ip地址只要确定了它的分类, 也就确定了网络标识和主机标识 A类: 0.0.0.0 - 127.0.0.0 B类: 128.0.0.1 - 191.255.0.0 C类: 192.168.0.0 - 229.255.255.0 D类: 224.0.0.0 - 239.255.255.255 没有主机标识, 用于多播 主机地址全0: 表示对应ip地址不可获知 主机地址全1: 用作广播地址; 广播分为 本地广播 和 直接广播.在本网络中的广播叫做本地广播, 此时ip地址的网络标识为该网络的地址, 主机标识为全1; 该ip会被路由器屏蔽, 所以不会到达其他的网段上; A网络下的主机向B网络广播叫做直接广播; 子网掩码为了解决分类造成ip地址浪费的情况. 因为同一链路网络标识相同, 已b类ip地址为例, 同一链路可架设六万多台主机, 但实际情况中一般不会出现这种情况, 因此造成了地址的浪费. 因此我们引入子网掩码, 使ip地址不再受限于分类. 格式: 网络标识位全1, 主机标识位全0 全局地址/私有地址为了解决ip地址分配不够的问题, 出现了私有地址. 全局地址在整个互联网保持唯一, 私有地址只需要在同一个域内保持唯一即可. 若配有私有ip的主机联网时, 则需通过NAT进行通信. 私有网络ip地址范围: A类: 10.0.0.0 - 10.255.255.255 B类: 172.16.0.0 - 172.31.255.255 C类: 192.168.0.0 - 192.168.255.255即所有10开头, 192.168开头, 和172开头的都是私有地址 路由控制路由表格式: ip地址 / 下一个路由器到达每个路由器后, 在路由表中找到符合目标地址的下一跳地址, 转发至下一个路由器; 直至找到目标网络; 分类默认路由ip地址为 0.0.0.0 或 default 主机路由ip地址为 x.x.x.x/32, 即所有整个ip的所有位都参与路由, 多用于不希望通过网络地址路由的情况. 环回地址localhost / 127.0.0.1是同一台计算机的程序进行网络通信所使用的默认地址, 使用该地址时, 数据包不会发送到网络上 MTU与分片MTU: 每种链路的最大传输单元; eg.以太网的MTU为1500因为帧大小有限制, 且不同链路的MTU值不尽相同. 因此, 必要时路由器会对ip数据包进行分片, 并在目标主机处进行重组 IPV6ARP以目标ip地址为线索, 用来获得 下一个应该接受数据包的网络设备的mac地址 ;当目标主机在同一链路上, 利用ARP广播直接获得目标主机的mac地址, 进行发送;当目标主机不在同一链路, 则通过ARP获得下一跳路由器的mac地址;获取到的mac地址会缓存到ARP缓存表中, 直至过期失效; (发送主机和目标主机都会进行mac地址缓存) RARP我们的个人电脑可以通过DHCP自动获取本机ip, 但使用例如打印机等嵌入设备, 就无法使用DHCP协议. 此时我们需要一台RARP服务器, 并在该服务器上注册设备的mac地址及其ip地址. 当设备启动后, 会发送获取ip地址的请求. ICMP用来辅助ip协议, 报告异常/获取路由, 子网掩码等网络信息 分类 目标不可达: 连接不到目标主机. 超时消息: 路由器发现某报文TTL为0, 就会像发送端发送该消息类型 回送消息: 发送ICMP回送请求消息, 收到ICMP回送应答消息. eg.ping命令就利用该消息实现 地址掩码消息: 向目标主机发送ICMP地址掩码请求消息, 就会受到对应的ICMP地址掩码应答消息 DHCP主机接入网络后, 自动获取tcp/ip通信所以需要的设置. (ip, 子网掩码, 默认路由, dns等等) 工作机制 客户端发出ip租用请求报文, 通过 UDP端口69 (DHCP请求默认端口)向网络中发送 DHCPDISCOVER 广播包; 该包中源ip: 0.0.0.0, 目的ip: 255.255.255.255 任何接收到 DHCPDISCOVER 广播包的DHCP服务器, 都会通过 UDP端口68 回复 DHCPOFFER 广播包, 来提供信息; 该包中源ip为DHCP服务器ip, 目标ip为255.255.255.255 客户机若收到不止一个DHCPOFFER包, 会选择收到的第一个, 并发送 DHCPREQUEST 包, 其中包含提供ip的DHCP服务器和选择的ip 没被选择的DHCP服务器收到DHCPREQUEST包后, 会撤销之前分配的ip, 以供下次使用; 被选择的DHCP服务器会广播发送 DHCPACK 确保所选ip可用DHCP服务器: 在分配ip地址前发送 ICMP回送请求包, 确认没有返回应答客户端: 向获得的ip发送ARP请求包, 确认没有返回应答DHCP中继代理通过DHCP中继代理, 对不同网段的ip地址分配也可以通过一个DHCP服务器来进行统一管理; 客户端会向DHCP中继代理发送广播包, 中继代理服务器收到请求后, 再以单播的形式发送给DHCP服务器 NAT用来在本网络中使用私有ip, 在连接互联网时转为全局ip的技术NAT有两种, 一种是替换ip, 但现在很少使用;另一种叫 NAPT, 它的工作原理是用网关的ip, 并分配一个临时会话的端口号; 对于NAPT又分为两个大类型: Symmetric NAT型 (对称型)即在网关中, 两个不同session, ip相同, 端口号不同. Cone NAT型（圆锥型, 占主流）两个不同session, ip和端口号都相同. (但因为目标地址不同, 所以也不是一个连接) TCP/UDP端口号通过端口号, 我们可以知道请求究竟是发给的哪个守护进程. 例如当收到tcp建立的连接请求时(通过ip首部字段可得知), 如果目标端口号为22, 则转给sshd(ssh守护进程), 如果是80则转给httpd(http守护进程).需要注意的是, 端口号由其使用的传输层协议决定, 因此不同传输协议可以使用相同的端口号. 但是知名端口号与传输层协议无关, 例如53端口无论是tcp还udp, 都是用于dns服务 分类 知名端口号: 0-1023eg. http:80 FTP:21 ssh:22 注册端口号: 1024-49151 时序分配法: 49152-65535 TCP确认应答 + 序列号 + 超时重传 (可靠传输)tcp通过确认应答实现可靠地数据传输. 在一定时间内没有等到确认应答, 发送端就会进行重发.确认应答是通过序列号实现的, 序列号是按顺序给发送数据的每个自己都编上号码. 接收端通过查询接受数据tcp首部中的序列号和数据长度(ip首部中的数据包长度 - ip首部长度 - tcp首部长度), 将自己下一次应该接受的序号作为确认应答发出去. MSS: 最大消息长度tcp在传送大量数据时, 以MSS的大小将数据进行分割发送. 进行重发时也是以MSS为单位.MSS是在三次握手时, 两端主机分别在tcp首部中写入自己的MSS, 并取较小值使用 窗口控制(提高速度)如果发送端每次等到确认应答后, 再发送下一个段, 包的往返时间会很长. 因此, tcp引入的窗口的概念.窗口大小: 无需等待确认应答而可以继续发送消息的最大值. 重发控制那么, 使用窗口后确认应答, 以及重发控制又是如何实现的呢?当接受主机收到一个自己应该接受的序号以外的数据时, 会对当前为止收到的数据返回确认应答. 而如果发送端主机连续三次收到同一个确认应答, 就会对其对应数据进行重发. 流控制如果接收端窗口已满, 并需要一段时间来处理消息, 此时发送端发送的数据就会被丢弃. 为了防止这种情况下网络流量的无端浪费, 我们引入了流控制. 拥塞控制","categories":[{"name":"网络","slug":"网络","permalink":"https://wenxuan-hao.github.io/categories/网络/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://wenxuan-hao.github.io/tags/网络/"}]},{"title":"断路器模式","slug":"断路器模式","date":"2019-12-22T15:34:05.000Z","updated":"2020-02-24T11:40:36.264Z","comments":true,"path":"断路器模式/","link":"","permalink":"https://wenxuan-hao.github.io/断路器模式/","excerpt":"介绍在分布式环境下，特别是微服务结构的分布式系统中， 一个软件系统调用另外一个远程系统是非常普遍的。这种远程调用的被调用方可能是另外一个进程，或者是跨网路的另外一台主机, 这种远程的调用和进程的内部调用最大的区别是，远程调用可能会失败，或者挂起而没有任何回应，直到超时。更坏的情况是， 如果有多个调用者对同一个挂起的服务进行调用，那么就很有可能的是一个服务的超时等待迅速蔓延到整个分布式系统，引起连锁反应， 从而消耗掉整个分布式系统大量资源。最终可能导致系统瘫痪。 断路器（Circuit Breaker）模式就是为了防止在分布式系统中出现这种瀑布似的连锁反应导致的灾难。","text":"介绍在分布式环境下，特别是微服务结构的分布式系统中， 一个软件系统调用另外一个远程系统是非常普遍的。这种远程调用的被调用方可能是另外一个进程，或者是跨网路的另外一台主机, 这种远程的调用和进程的内部调用最大的区别是，远程调用可能会失败，或者挂起而没有任何回应，直到超时。更坏的情况是， 如果有多个调用者对同一个挂起的服务进行调用，那么就很有可能的是一个服务的超时等待迅速蔓延到整个分布式系统，引起连锁反应， 从而消耗掉整个分布式系统大量资源。最终可能导致系统瘫痪。 断路器（Circuit Breaker）模式就是为了防止在分布式系统中出现这种瀑布似的连锁反应导致的灾难。 一旦某个电器出问题，为了防止灾难，电路的保险丝就会熔断。断路器类似于电路的保险丝， 实现思路非常简单，可以将需要保护的远程服务嗲用封装起来，在内部监听失败次数， 一旦失败次数达到某阀值后，所有后续对该服务的调用，断路器截获后都直接返回错误到调用方，而不会继续调用已经出问题的服务， 从而达到保护调用方的目的, 整个系统也就不会出现因为超时而产生的瀑布式连锁反应。 基本模式当supplier可用时, 断路器会直接返回调用结果给client端; 多次重试后达到重试阈值, 断路器会从close模式转为open模式, 再次调用相同的服务, 断路器会直接返回错误. 扩展模式基本的断路器模式下，保证了断路器在open状态时，保护supplier不会被调用， 但我们还需要额外的措施可以在supplier恢复服务后，可以重置断路器。一种可行的办法是断路器定期探测supplier的服务是否恢复， 一但恢复， 就将状态设置成close。断路器进行重试时的状态为半开（half-open）状态。 应用场景一个supplier一般很稳定，如果一旦故障发生后， 检查和恢复需要的时间比较长，通常无法短时间内快速修复的，那么这种服务比较适合采用断路器模式。否则很可能导致ping-pong效应。 不适用场景为了防止一个应用程序试图调用一个远程服务或访问共享资源，如果​​该操作是极有可能失败， 这种模式可能不适合。 对于处理中的应用程序访问本地专用资源，例如在存储器内数据结构。在这种环境下通常也不适合，使用断路器只会增加系统开销。 golang版实现","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://wenxuan-hao.github.io/categories/设计模式/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://wenxuan-hao.github.io/tags/设计模式/"}]}]}